\chapter{Background and Related Work}
\label{chap:related}

In this chapter we are going to present the mechanics of some kind of fuzzers
and some specific implementations of \acfp{CGF}. Then we move on presenting
efforts of researchers trying to combine different fuzzing engines or testing
techniques with the aim of improving performance or efficiency.

\section{Black-Box Mutational Fuzzing}
\label{sec:bbfuzz}
Black-box \emph{mutational} fuzzing (or \emph{Random Testing}) is a simple
testing technique that uses mutation operators on a sample input to produce a
new input; a corpus of \emph{valid} files (the more the better) is required to
achieve good efficiency by reducing the search space. A simple algorithmic
representation is given in Algorithm~\ref{algo:bbfuzzing}.

\begin{algorithm}
    \DontPrintSemicolon%
    \SetKwFunction{SelectSeed}{SelectSeed}
    \SetKwFunction{MutateSeed}{MutateSeed}
    \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
    \Input{Set of samples $S$}
    \Output{Set of crashing inputs $C$}
    \BlankLine%
    $C \leftarrow \emptyset$\;
    \While{stop condition is not met}{%
        $t \leftarrow \SelectSeed{S}$\;\nllabel{algo:bbfuzzing:ss}
        $t^\prime \leftarrow \MutateSeed{t}$\;\nllabel{algo:bbfuzzing:ms}
        \If{$t^\prime$ crashes program}{%
            $C \leftarrow C \bigcup \{t^\prime\}$\;
        }
    }
    \caption{Black-box mutational fuzzing}
\label{algo:bbfuzzing}
\end{algorithm}

The main algorithm works within a loop that stops at a predetermined condition
such as the end of a time budget, after the first crash has been found or after
a certain number of inputs have been tested, to name a few. More rudimentary
tools such as \textbf{zzuf}~\cite{hocevar2011zzuf} or
\textbf{Radamsa}~\cite{helin2015radamsa} allow for the tester to apply his or
her own stop criteria for the fuzzing campaign. The \texttt{SelectSeed} function
on line~\ref{algo:bbfuzzing:ss} of Algorithm~\ref{algo:bbfuzzing} selects one
input from the seeds corpus using the strategy of choice (\eg~stochastically, by
execution time, crash density). Next, the \texttt{MutateSeed} function applies a
mutation operator (\eg~bit-flips, insertion or deletion of words) to the
selected input to create a new one which is then fed to the \ac{SUT}. Different
mechanisms can then be deployed to identify whether the program crashed under
the given input, often program or \ac{OS} specific; if the \ac{SUT} exhibits a
fault, the test case is stored with useful information about the occurred fault
to later report about it to the tester.

Tools like zzuf or Radamsa only implement the \texttt{MutateSeed} function on
line~\ref{algo:bbfuzzing:ms}, leaving the remaining components' implementation
to the tester. For example zzuf applies random bit-flips to its input using a
set \emph{mutation ratio} (how much of the input to change) fully configurable
by the user within an interval or fixed. Radamsa performs instead a number of
more sophisticated mutation operators such as insert, repeat, drop and swap on
entities like bytes, ASCII and Unicode texts or arithmetic manipulations. More
complex black-box mutational fuzzers implement all components of
Algorithm~\ref{algo:bbfuzzing} and are able to exploit knowledge of the running
campaign to achieve better results.
The \textbf{\acf{BFF}}~\cite{householder2012probability} uses \emph{crash
density} as a metric to decide which pair of seed input and mutation ratio to
use for the next call to \texttt{MutateSeed} (\ac{BFF} uses indeed zzuf within
its mutation engine). Crash density of a seed is defined as the number of
crashes found by fuzzing that seed, divided by the number of total test cases
generated by the seed. Each execution of a mutated seed is modeled as a
Bernoulli trial where the outcome is whether or not the \ac{SUT} exhibited a
defect. The Binomial distribution that would result from successive trials is
approximated by a Poisson distribution as the number of trials is much higher
than the number of times a fault is found. The upper bound of the $95\%$
confidence interval of that distribution is then used to compute the probability
$p_i$ of selecting the seed file $t_i$. The same process is applied for a single
seed file and a fixed set of mutation ratio ranges so that for each seed file
there is a probability distribution over the set of ranges.
\citeauthor{woo2013scheduling} give the name \ac{FCS}~\cite{woo2013scheduling}
to describe the problem of selecting the next seed and mutation ratio pair to
fuzz (what they call a \emph{fuzzing configuration}) and recognize the
\ac{MAB}~\cite{berry1985bandit} nature of the problem. The authors take one step
further by modeling black-box mutational fuzzing as a weighted version of the
Coupon Collector's Problem and use those insights to inspect the \ac{FCS}
problem along three different axes that allows them to compose and evaluate a
total of 26 \ac{MAB} algorithms.

\section{Coverage-Based Gray-Box Fuzzing}
\label{sec:cgf}

A \ac{CGF} uses lightweight instrumentation and monitoring of the \ac{SUT} to
gain coverage information. This information is then exploited to provide a
solution to the \ac{FCS}
problem~\cite{afltech,lemieux2017fairfuzz,bohme2017directed,bohme2017coverage}.
The general approach is described in Algorithm~\ref{algo:cgf}.

\begin{algorithm}
    \DontPrintSemicolon%
    \SetKwFunction{SelectNext}{SelectNext}
    \SetKwFunction{AssignEnergy}{AssignEnergy}
    \SetKwFunction{MutateInput}{MutateInput}
    \SetKwFunction{IsInteresting}{IsInteresting}
    \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
    \Input{Set of seed inputs $S$}
    \Output{Set of crashing inputs $C$}
    \BlankLine%
    $C \leftarrow \emptyset$\;
    $Q \leftarrow S$\;
    \If{$Q = \emptyset$}{$Q \leftarrow \{\text{empty file}\}$}
    \Repeat{timeout reached or abort signal received}{%
        $t \leftarrow \SelectNext{Q}$\;\label{algo:cgf:sn}
        $p \leftarrow \AssignEnergy{t}$\;\label{algo:cgf:ae}
        \For{$i\in\left[0 \dots p\right]$}{%
            $t^\prime \leftarrow \MutateInput{t}$\;\label{algo:cgf:mi}
            \uIf{$t^\prime$ crashes}{%
                $C \leftarrow C \bigcup \left\{t^\prime\right\}$\;
            }
            \ElseIf{\IsInteresting{$t^\prime$}\label{algo:cgf:ii}}{%
                $Q \leftarrow Q \bigcup \left\{t^\prime\right\}$\;
            }
        }
    }
    \caption{Coverage-based Gray-box Fuzzing}
\label{algo:cgf}
\end{algorithm}

The first difference from black-box mutational fuzzing is that a \ac{CGF} does
not need a corpus of seed files to work properly (although it would be more
efficient). \citeauthor{afl}, the author of AFL, was able to generate valid JPEG
images starting from an empty file~\cite{afljpeg}. The functions
\texttt{SelectNext} and \texttt{MutateInput} (at lines~\ref{algo:cgf:sn}
and~\ref{algo:cgf:mi} respectively) are analogues of \texttt{SelectSeed} and
\texttt{MutateSeed} of Algorithm~\ref{algo:bbfuzzing}. The framework of
Algorithm~\ref{algo:cgf} incorporates explicitly the mechanics that \emph{smart}
black-box mutational fuzzers like \ac{BFF} implement. The function
\texttt{AssignEnergy} at line~\ref{algo:cgf:ae} decides how much effort should
be put in fuzzing the selected test-case (\eg~how many mutated inputs should be
created from it). Another difference from black-box mutational fuzzers is the
\texttt{IsInteresting} function at line~\ref{algo:cgf:ii}, responsible to
determine whether the mutated input is deemed \emph{interesting} and worth
fuzzing; this allows for \acp{CGF} to build a corpus of test-cases that could
even be reused with other tools or to fuzz another software that accepts the
same file format. For \acp{CGF}, interesting, loosely means that increases code
coverage and by keeping a queue of test-cases with ever-increasing coverage
helps fuzzers of this kind reaching deeper portions of the \ac{SUT} compared to
black-box mutational fuzzers.

\subsection{American Fuzzy Lop}
% - AFL-likes: AFL, AFLFast, FairFuzz
AFL~\cite{afl} is one of the most well known \acp{CGF}. Its focus is not on any
singular principle or insights but is rather a collection of hacks that have
been tested and proved effective in practice; the governing principles for its
development are speed, reliability and ease of use~\cite{afltech}. AFL gets its
coverage feedback from the \ac{SUT} by instrumenting its compiled binary. This
is done by injecting specific locations of the \ac{SUT} with a monitoring
snippet of code. This code can be injected by compiling the \ac{SUT} with the
\texttt{afl-gcc} utility or, when the source code is not available, AFL uses
QEMU~\cite{bellard2005qemu} to dynamically (during interpretation, at runtime)
instrument the binary. AFL-dyninst~\cite{afldyn} is an extension to AFL that
injects the instrumentation snippet directly into the binary. What AFL injects
into the \ac{SUT} is essentially equivalent to that presented in
Listing~\ref{lst:aflbininst}.

\begin{lstlisting}[caption={AFL's instrumentation},label=lst:aflbininst,float]
    cur_location = <COMPILE_TIME_RANDOM>;
    shared_mem[cur_location ^ prev_location]++;
    prev_location = cur_location >> 1;
\end{lstlisting}

The instrumentation snippet is injected at every branch within the instrumented
code. The \texttt{cur\_location} variable is generated randomly at compile time
and identifies the current \emph{basic block} (a straight code sequence without
branches besides at its entry and exit points). The \texttt{shared\_mem} array
is a 64KB shared memory region provided by the fuzzer; each byte of the shared
memory can be thought of as a hit to a transition from one branch to another.
The shift operation at the last line preserves directionality of the tuples
(\eg~$A \oplus B$ would be indistinguishable from $B \oplus A$) and to keep the
identity of loops within the same basic block (\eg~$A \oplus A$ would be equal
to $B \oplus B$).

With regards to Algorithm~\ref{algo:cgf}, AFL implements the \texttt{SelectNext}
function by classifying elements of the queue as \emph{favorites}. A test-case
is deemed favorite if it exhibits faster speed of execution and small size for
the branch tuples that it covers compared to the other test-cases in the queue.
AFL selects favorite items more often, implementing a strategy that favors,
using the \ac{MAB} terminology, exploitation against exploration
\cite{bohme2017coverage}. AFL initially applies a set of deterministic mutation
operators to selected inputs and later uses what it calls an \emph{havoc stage}
where more complex and stacked mutations are stochastically applied; the
function \texttt{AssignEnergy} determines how many mutations should be applied
to the selected test-case during the havoc stage. AFL's implementation of
\texttt{AssignEnergy} uses a mix of execution speed, coverage information and
age of the selected test-case to determine how many inputs should be generated
by mutating it. AFL implements a good number of mutation operators such as
bit-flips, insertion and deletion of bytes, arithmetic operators, to name a few
\cite{aflmut}. The function \texttt{IsInteresting} as implemented by AFL,
returns true if the input $t^\prime$ exercises a new basic block transition or
if the number of times a transition is hit goes from one range of values to the
next; AFL employs a ``bucketing'' scheme where the range of values required to
be in the next bucket roughly doubles (the exact values are $1$, $2$, $3$,
$4-7$, $8-15$, $16-31$, $32-127$ and $128+$)~\cite{afltech}.

\subsubsection{AFLFast}
\citeauthor{bohme2017coverage} model Coverage-based Gray-Box Fuzzing as the
systematic exploration of the state space of a Markov chain, where the state
space is composed by all the possible paths that the \ac{SUT} can
take~\cite{bohme2017coverage}. This allows them to conduct a mathematical
analysis of the challenges faced by \acp{CGF} such as AFL\@. By observing that
an high proportion of test-cases generated by AFL exercise a small number of
\emph{high frequency paths} (\ie~states of the Markov chain that are visited
more often), the authors draw the intuition that steering fuzzing more toward
\emph{low frequency paths} could lead to an improvement in performance
(exploring more paths with the same amount of fuzz). This intuition is
implemented into AFLFast, an extension of AFL\@. In reference to
Algorithm~\ref{algo:cgf}, AFLFast replaces the \texttt{SelectNext} and the
\texttt{AssignEnergy} functions with new implementations.

The authors discuss and evaluate different power schedules, responsible of
assigning energy to a selected test-case $t_i$ exercising path $i$. Besides two
of them (which use a constant schedule), the other power schedules are functions
of two values: $s(i)$, the number of times $t_i$ has already been selected from
the queue and $f(i)$, the number of generated inputs that exercise path $i$. The
former allows for power schedules that assign more energy the more the test-case
is selected; the latter serves as an approximation of the stationary
distribution of the Markov chain and allows for power schedules that assign
energy inversely proportional to the density, effectively directing more fuzzing
efforts towards low density regions of the distribution. AFLFast implements nine
power schedules: two constant schedules (one of which is the same used by AFL)
that assign the same amount of energy every time the test-case is picked from
the queue; seven monotonous schedules that assign an increasing amount of energy
every time the test-case is picked from the queue.

The same two metrics used in the monotonous power schedules are also used to
devise two search strategies: one prioritizes inputs with small $s(i)$
(\ie~test-cases that have not been selected often), one prioritizes inputs with
small $f(i)$ (\ie~inputs that exercise a low frequency path). These strategies
are not mutually exclusive and can be used together: first is searched the input
with the smallest $s(i)$, if more than one is found it proceeds searching for an
input with the smallest $f(i)$; if more than one exists, AFLFast falls back to
AFL's strategy (based on input size and execution time).

The presented evaluation of AFLFast over common UNIX utilities shows that the
exponential schedule works best, assigning energy inversely proportional to
$f(i)$ and directly proportional to $2^{s(i)}$. The comparison of search
strategies shows that the combination of both strategies outperforms
significantly both strategies individually and AFL's strategy. AFLFast shows
promising results when directly compared with AFL\@. When both AFL and AFLFast
are able to discover (within the given time budget) the same vulnerability,
AFLFast does it much quicker; at the same time it is able to expose
vulnerabilities that AFL could not discover.

\subsubsection{FairFuzz}
\citeauthor{lemieux2017fairfuzz} devise another extension to AFL that targets
\emph{rare branches} with the aim to drive the fuzzing process deeper into the
\ac{SUT}~\cite{lemieux2017fairfuzz}. FairFuzz changes how the
\texttt{SelectNext} and \texttt{MutateInput} functions of
Algorithm~\ref{algo:cgf} work. When selecting inputs from the queue, FairFuzz
prioritizes test-cases that exercise a rare branch; successively new fuzz is
produced by applying byte-level mutation operators to the selected input trying
to exercise the same rare branches while still exploring new parts of the
\ac{SUT}. The intuition behind this is that for most file formats, there are
sequences of bytes acting as headers to prove the validity of the file format
and other bytes that trigger execution of various parts of the program that
processes the file. Among all the fuzz generated by AFL, only a few will contain
the right sequence of bytes in the right place; FairFuzz may classify branches
triggered by this header as rare and apply mutation operators that preserve the
header in the generated fuzz. More specifically a branch is rare if it is hit by
a number of inputs (amount of fuzz) smaller than the \emph{rarity cutoff}. This
threshold is computed after each call to \texttt{SelectNext} as $2^i$ where
$2^{i-1} < \min(B_{hit}) \le 2^i$ and $B_{hit}$ is the set of hit counts for all
branches discovered so far. At the core of the mutation operators instead, the
authors describe the concept of \emph{branch mask}, an artifact used to
determine at which positions in the input bytes can be overridden, deleted or
inserted. The branch mask, computed during the deterministic stage of mutation,
is then used to steer mutation in the havoc stage so that rare branches are
still covered by the mutated input.

\subsection{Honggfuzz}
Honggfuzz~\cite{honggfuzz} is another general-purpose \ac{CGF} which simplifies
the semantics of Algorithm~\ref{algo:cgf} but offers state-of-the-art
implementation that grants huge throughput (generates lots of fuzz, especially
in persistent mode). The most peculiar feature of Honggfuzz is allowing the user
to gather feedback from the \ac{SUT} via software or hardware sources; it
supports CPU branch and instruction counting by means of Intel \ac{BTS} or Intel
\ac{PT} on supported CPUs. Honggfuzz selects uniformly at random one input to
mutate from the queue and assigns constant energy of $1$ to it. The
\texttt{MutateInput} function picks uniformly at random one of the implemented
mangling functions and applies it to the selected input. Honggfuzz considers a
new input interesting if the used coverage metric increases; if using Intel
\ac{BTS} for example, Honggfuzz maintains a bitmap containing branch coverage
information (similar to the one used by AFL) and any fuzz exercising a
previously unseen branch is considered interesting and added to the queue.

\subsection{VUzzer}
VUzzer~\cite{rawat2017vuzzer} is an \emph{evolutionary} gray-box fuzzer that
uses lightweight static and dynamic analysis to gain knowledge about control-
and data-flow features of the \ac{SUT}, which is then exploited to deploy an
\emph{application-aware} mutation strategy. VUzzer follows the same
population-based model of \acfp{EA} for which a generic representation is given
in Algorithm~\ref{algo:ea}.

\begin{algorithm}
    \DontPrintSemicolon%
    \SetKwFunction{Initialize}{Initialize}
    \SetKwFunction{Evaluate}{Evaluate}
    \SetKwFunction{ParSelect}{SelectParents}
    \SetKwFunction{Recombine}{Recombine}
    \SetKwFunction{Mutate}{Mutate}
    \SetKwFunction{SurSelect}{SelectSurvivors}
    \SetKwData{Pop}{Population}
    \SetKwData{Parents}{Parents}
    \SetKwFunction{Off}{Offspring}

    $\Pop \leftarrow \Initialize$\;
    $E \leftarrow \Evaluate{\Pop}$\;
    \Repeat{Stop criteria are met}{%
        $\Parents \leftarrow \ParSelect{\Pop, E}$\;
        $\Off \leftarrow \Recombine{\Parents}$\;
        $M \leftarrow \Mutate{\Off}$\;
        $E \leftarrow \Evaluate{M}$\;
        $\Pop \leftarrow \SurSelect{M, E}$\;
    }
    \caption{General scheme for an \ac{EA}}
\label{algo:ea}
\end{algorithm}

After the population is initialized it is evaluated using a \emph{fitness
function}. The population then undergoes the iterative evolutionary process
composed of three phases:

\begin{itemize}
    \item \textbf{parent selection}: a set of parents is selected from the
        population pool using the chosen strategy and the fitness scores
        (typically the strategy is probabilistic prioritizing individuals with
        better fitness score);
    \item \textbf{variation operators}: there are two kinds of variation
        operators typically used in \acp{EA}: recombination operators take two
        or more parents and combines them to produce an offspring; mutation
        operators instead are unary;
    \item \textbf{survivor selection}: the offspring is evaluated and selection
        techniques similar to the ones used in parent selection are applied to
        select the best individuals from the offspring to generate the
        population pool for the next iteration.
\end{itemize}

VUzzer uses static and dynamic analysis on the \ac{SUT}'s binary to deploy
enhanced application aware mutation operators and derive a fitness function that
uses control-flow features of the binary alongside code coverage. Before
starting the main fuzzing loop, VUzzer uses an intra procedural static analyzer
which objective is two-fold
\begin{enumeratein}
    \item enumerate all immediate values from \texttt{cmp} instructions
    \item for each function, compute the \ac{CFG} and model it as a Markov Chain
        such that to each basic block is assigned a \emph{weight} that is the
        inverse of the probability of reaching it.
\end{enumeratein}
The set of immediate values is what the application might expect as input at
certain offsets and VUzzer uses these values to mutate the offspring in the main
fuzzing loop. The set of weights is instead used alongside a set of
\emph{error-handling basic blocks} to compute the fitness score. In contrast to
other \acp{CGF} like AFL or Honggfuzz, VUzzer requires a minimal set of valid
inputs to initialize the set of error-handling basic blocks, which is then
incrementally developed during fuzzing. After collecting the set of basic blocks
exercised by these initial inputs, VUzzer proceeds at throwing totally random
inputs at the \ac{SUT} and marks basic blocks that where not executed by any of
the valid inputs as error-handling basic blocks. This knowledge is then used to
penalize individuals that execute such basic blocks, which is done by properly
setting the weight for the corresponding basic block. VUzzer uses Intel's Pin
\cite{luk2005pin} to dynamically instrument the binary and gather the trace of
basic blocks exercised by the \ac{SUT} under a certain input.

Dynamic binary instrumentation is not the only dynamic technique used by VUzzer.
\ac{DTA} allows to monitor a \emph{tainted} input within the \ac{SUT} and gather
information about code that operates on it. VUzzer uses \ac{DTA} to monitor
\texttt{cmp} and \texttt{lea} instructions that are tainted by the input: from
the former it extracts the set of offsets in the input that taint the operands
(with byte-level granularity); for the latter it tracks the index register and
extracts all offsets that taint those indexes. As \ac{DTA} is not a lightweight
technique, VUzzer uses it only at initialization on the seeds corpus and on
inputs that exercise previously unseen basic blocks during the main fuzzing
loop. \ac{DTA} is at the core of VUzzer's \emph{magic byte detection} algorithm:
at initialization it exploits the available valid inputs to extract bytes within
the input placed at a certain (unique) offset in all valid inputs and later
builds on this knowledge.

Ultimately, the knowledge acquired through static and dynamic analysis is
exploited by recombination and mutation operators. VUzzer always applies a
\emph{single-point crossover} operator that, given two inputs, breaks them at a
randomly picked cut point and then recombines parts of different parents to
produce two children. Mutation operators follows with a fixed probability,
producing a new child from a single parent. Those operators are application
aware, making use of results from static (\eg~immediate values of \texttt{cmp}
instructions) and dynamic (\eg~magic bytes, offsets that taint the index operand
of \texttt{lea} instructions) analyses.

\section{Symbolic-Assisted Fuzzing}
% introduction to fuzzing with white box approach
Automated test generation has been done since the 1970s with the aid of symbolic
execution. Initial work focused on finding inputs to exercise a specific
execution path within the \ac{SUT}. More recently, symbolic execution has seen a
resurgence in the context of security testing, given that it has been proven
effective in exploring all feasible execution paths within real-word programs.

\begin{algorithm}
    \DontPrintSemicolon%
    \SetKwFunction{RunAndCheck}{RunAndCheck}
    \SetKwFunction{SelectNext}{SelectNext}
    \SetKwFunction{ExpandExecution}{ExpandExecution}
    \SetKwFunction{Score}{Score}
    \KwIn{Initial seed $t_s$}
    \KwOut{Set of crashing inputs $C$}
    \BlankLine%
    $C \leftarrow \emptyset$\;
    $Q \leftarrow \{t_s\}$\;\label{algo:symfuzz:initq}
    \If{\RunAndCheck{$t_s$}\label{algo:symfuzz:checkseed}}{%
        $C \leftarrow C \bigcup \{t_s\}$
    }
    \While{$Q$ is not empty}{%
        $t \leftarrow \SelectNext{Q}$\;\label{algo:symfuzz:sel}
        $G \leftarrow \ExpandExecution{t}$\;\label{algo:symfuzz:exp}
        \ForEach{$t_G \in G$}{%
            \If{\RunAndCheck{$t_G$}}{%
                \label{algo:symfuzz:gen1}
                $C \leftarrow C \bigcup \{t_G\}$
            }
            \Score{$t_G$}\;\label{algo:symfuzz:score}
            $Q \leftarrow Q \bigcup \{t_G\}$\;\label{algo:symfuzz:gen2}
        }
    }
    \caption{Symbolic-Assisted Fuzzing}
\label{algo:symfuzz}
\end{algorithm}

An abstract view of a generic symbolic-assisted fuzzing engine is given in
Algorithm~\ref{algo:symfuzz}. It maintains a set of inputs, initialized with the
initial seed input (line~\ref{algo:symfuzz:initq}), from which new inputs are
generated. On line~\ref{algo:symfuzz:checkseed} the function
\texttt{RunAndCheck} runs the \ac{SUT} with the given input and returns a true
value if the program ended with unexpected results. If this is the case, the
input that caused the failure is added to a set which is returned at the end of
the procedure. Next, a loop operates until the set of working inputs is empty.
First it selects an element from the set (through \texttt{SelectNext} on
line~\ref{algo:symfuzz:sel}) and then generating a set of inputs from the
selected input on line~\ref{algo:symfuzz:exp}. \texttt{ExpandExecution}
symbolically executes the \ac{SUT} with the supplied input and collects the path
constraint. The constraint that identifies the $i$th branch in the execution is
negated so that when the updated path constraint is solved for the symbolic
variables, the new input is going to exercise the same path as its parent up to
the $(i-1)$th branch and take the alternative branch on the $i$th one. Later,
each generated input is run and checked for exceptions, before being scored and
added to the set of working inputs (line~\ref{algo:symfuzz:gen1}
to~\ref{algo:symfuzz:gen2}). \texttt{Score} evaluates the given input and assign
a score that can be used in successive calls to \texttt{SelectNext}.

% DART
The specifics of each component of Algorithm~\ref{algo:symfuzz} is different
from one implementation to another. The most peculiar ones, that differentiate
the most symbolic-assisted fuzzers among each other,
are\linebreak\texttt{SelectNext} (line~\ref{algo:symfuzz:sel}),
\texttt{ExpandExecution} (line~\ref{algo:symfuzz:exp}) and \texttt{Score}
(line~\ref{algo:symfuzz:score}). DART~\cite{Godefroid2005DARTDA} provides a
reference implementation for white box fuzzing. The set of working inputs
consists at most of a single element (the seed input is randomly generated),
\texttt{SelectNext} always returns the only element present and
\texttt{ExpandExecution} returns a singleton set which input is the result of
running the constraint solver on a modified version of the path constraint
exercised by its given input; \citeauthor{Godefroid2005DARTDA}, for exposition
purposes, present a depth-first search on the execution tree of the \ac{SUT}
(\ie~the last constraint on the path constraint is negated before being fed to
the solver), although other search strategies can be used (\eg~breadth-first,
random or heuristics-based). When the program is symbolically executed with a
generated input, DART checks that there are no divergences (\ie~the expected
path is effectively taken) and if so generates a new input; otherwise it flips
some flags tracking search incompleteness and restarts the procedure with a new
randomly generated input.

% SAGE
SAGE~\cite{godefroid2008automated, godefroid2012sage} expands upon the work on
DART in a threefold manner:
\begin{enumeratein}
    \item by leveraging concolic execution on x86 binaries (in contrast to C
        source code);
    \item implementing a generational search in order to optimize the time spent
        doing symbolic execution;
    \item testing the \ac{SUT} in its entirety instead of units of code.
\end{enumeratein}
The set of working inputs is initialized with a well-formed, valid input
(instead of randomly generated). \texttt{SelectNext} selects the input with the
highest score. SAGE scores each input with the number of newly discovered basic
blocks (\eg~input $i$ is assigned a score of $n$ if it exercise $n$ previously
unexercised basic blocks). \texttt{ExpandExecution} implements the generational
search: for each constraint on the path constraint it generates a new input by
negating it; to prevent redundancy in the sub-searches, a \texttt{bound}
parameter for each sub-search is used to limit backtracking above the branch
where the sub-search forked. The rationale behind this search strategy is to
maximize the number of generated inputs from each symbolic execution (which are
expensive for large programs with large amounts of symbolic variables); the
authors report a mean time to complete a single symbolic execution run for one
of the analyzed \ac{SUT} of 25 minutes and 30 seconds while testing the same
program takes seconds. Using a generational search strategy, SAGE is able to
spend only 25\% of the search time doing symbolic execution. Because of the
nature of this search strategy, it is critical to the effectiveness of SAGE that
the seed input exercises a path as deep as possible so that the first symbolic
execution generates as much new inputs as possible.

% online vs offline symbolic execution
The symbolic execution engine of SAGE is trace-based: the \ac{SUT} is executed
concretely and a trace of the execution is stored into a file; later this trace
is interpreted symbolically and reasoned about. Other symbolic-assisted fuzzers
(\eg~EXE~\cite{cadar2008exe} and KLEE~\cite{cadar2008klee}) take a different
approach: the \ac{SUT} is (usually) translated to an intermediate language and
interpreted; at branching statements the state of the \ac{SUT} is stored and
execution is forked. These approaches are named respectively offline and online
symbolic execution in literature. A disadvantage of the former is the redundancy
in re-executing instructions symbolically, while the latter puts a strain on
memory because of the continuous forking of state.
MAYHEM~\cite{cha2012unleashing} takes instead an hybrid approach: the system
starts with an online exploration phase in which normal online symbolic
execution is performed; then, whenever memory utilization reaches a threshold, a
checkpoint manager selects an active execution and stores a checkpoint
containing only the symbolic execution state, freeing memory. When there are no
more active executions, a checkpoint restoration phase selects a checkpoint and
restores it in memory by re-executing the \ac{SUT} only concretely, as the
symbolic state was stored in the checkpoint. After this, the system restarts
online exploration. This hybrid approach allows MAYHEM to be resilient to memory
requirements while avoiding redundant and expensive symbolic executions, taking
the best of online and offline symbolic execution.

% EXE and KLEE
EXE uses a coverage-based strategy to implement \texttt{SelectNext}: it selects
the input that exercises a path that is blocked (\ie~waiting to be scheduled for
execution) on an instruction that has been executed the fewest number of times;
then the selected input and its children are expanded
(\ie~\texttt{ExpandExecution}) in a depth-first manner. KLEE uses two different
search strategies in a round robin fashion. Random path selection uses a random
walk from the root of a binary tree representing all visited execution states
and stops when it reaches a leaf (\ie~leaves are active states while internal
nodes are places where execution forked). This strategy favors states high up in
the tree, which have the favorable property of having less constraints on their
symbolic inputs; moreover it makes it hard for the search to become stuck on
states generated by a tight loop containing symbolic variables (what the authors
call ``fork bombing''). Coverage-optimized search uses heuristics to assign
weights to states and uses them to perform random selection.

\section{Hybrid Techniques}
% Hybrid Fuzz Testing
Hybrid techniques merge symbolic-assisted fuzzing with black box mutational
fuzzing (\ie~random testing). Hybrid Fuzz Testing~\cite{pak2012hybrid} uses an
initial round of symbolic execution to find its way to a fixed, configurable,
number of ``frontier nodes''; for each node a path constraint is collected
(\ie~a frontier node is the basic block at the end of one of those paths). Then
new inputs are randomly generated that still respect the path predicates on each
frontier node; these inputs are then executed concretely to check for
exceptions. While this approach can help exploring the execution tree in its
breadth early on (something random testing struggles to achieve), random testing
can get stuck on deeper checks that have not been explored by an initial
symbolic execution run.

% Hybrid Concolic Testing & Driller

\section{Cooperative Fuzzing}
% TODO: Levy flights & Chemotactic

% TODO: brief of how we tackle the problem of using different fuzzers and island
% model for co-evolution

